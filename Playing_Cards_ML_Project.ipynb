{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA1eqmKjVhzv"
      },
      "source": [
        "#**Display and Preprocess Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6vBRzlGVvgT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y95j5ZtqVk9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcf2d15-5141-45c9-9d7d-915d694ba162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# get dataset\n",
        "base_path = '/content/drive/MyDrive/ml-project'\n",
        "dataset_zip = '/content/drive/MyDrive/ml-project/cards-set.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2TD3jM5Wqx9"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "def preprocess_image(image_data):\n",
        "  image = Image.open(BytesIO(image_data)).convert('RGB')\n",
        "  image = image.resize(IMG_SIZE)\n",
        "\n",
        "  # normalize pixel values to 0-1 range\n",
        "  image_array = np.array(image)\n",
        "  image_array = image_array / 255.0\n",
        "  return image_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS4WdgQ0XMj3"
      },
      "outputs": [],
      "source": [
        "def extract_and_preprocess_images(zip_ref, folder):\n",
        "  # get list of all files in the zip\n",
        "  all_files = zip_ref.namelist()\n",
        "\n",
        "  # filter for specified folder (train, valid, or test)\n",
        "  data_files = [f for f in all_files if f.startswith(folder) and f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "  preprocessed_imgs = []\n",
        "  img_labels = []\n",
        "\n",
        "  for img_file in data_files:\n",
        "    img_data = zip_ref.read(img_file)\n",
        "    preprocessed_img = preprocess_image(img_data)\n",
        "    preprocessed_imgs.append(preprocessed_img)\n",
        "\n",
        "    # extract the label (class) from the file path\n",
        "    label = os.path.basename(os.path.dirname(img_file))\n",
        "    img_labels.append(label)\n",
        "\n",
        "  return preprocessed_imgs, img_labels, data_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhJwjs6ZY4oz"
      },
      "outputs": [],
      "source": [
        "def display_imgs(zip_ref, data_files, title, preview_num):\n",
        "  class_dirs = set(os.path.dirname(f) for f in data_files)\n",
        "\n",
        "  for class_dir in class_dirs:\n",
        "    # get first n (preview_num) images for the current class\n",
        "    class_imgs = [f for f in data_files if os.path.dirname(f) == class_dir][:preview_num]\n",
        "\n",
        "    print(f'Class: {class_dir} - {title}')\n",
        "    fig, axes = plt.subplots(1, preview_num, figsize=(2 * preview_num, 2))\n",
        "\n",
        "    for i, img_file in enumerate(class_imgs):\n",
        "      img_data = zip_ref.read(img_file)\n",
        "      img = mpimg.imread(BytesIO(img_data), format='jpg')\n",
        "      axes[i].imshow(img)\n",
        "      axes[i].axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBFkDc9FfiUd"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode_labels(labels):\n",
        "  # convert to numpy array and reshape\n",
        "  labels_array = np.array(labels).reshape(-1, 1)\n",
        "\n",
        "  # check unique labels and their count\n",
        "  unique_labels = np.unique(labels_array)\n",
        "  print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "  print(f\"Unique labels: {unique_labels}\")\n",
        "\n",
        "  # perform one-hot encoding\n",
        "  one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "  one_hot_encoded_labels = one_hot_encoder.fit_transform(labels_array)\n",
        "\n",
        "  # verify the shape of the one-hot encoded labels\n",
        "  print(f'Shape of one-hot encoded labels: {one_hot_encoded_labels.shape}')\n",
        "  # printing the first encoded label\n",
        "  print(one_hot_encoded_labels[0])\n",
        "\n",
        "  return one_hot_encoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0zkjytZDZ5fh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299b0f24-2add-4111-e5f9-7905ef843c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----PROCESSING TRAINING DATA-----\n",
            "Number of unique labels: 53\n",
            "Unique labels: ['ace of clubs' 'ace of diamonds' 'ace of hearts' 'ace of spades'\n",
            " 'eight of clubs' 'eight of diamonds' 'eight of hearts' 'eight of spades'\n",
            " 'five of clubs' 'five of diamonds' 'five of hearts' 'five of spades'\n",
            " 'four of clubs' 'four of diamonds' 'four of hearts' 'four of spades'\n",
            " 'jack of clubs' 'jack of diamonds' 'jack of hearts' 'jack of spades'\n",
            " 'joker' 'king of clubs' 'king of diamonds' 'king of hearts'\n",
            " 'king of spades' 'nine of clubs' 'nine of diamonds' 'nine of hearts'\n",
            " 'nine of spades' 'queen of clubs' 'queen of diamonds' 'queen of hearts'\n",
            " 'queen of spades' 'seven of clubs' 'seven of diamonds' 'seven of hearts'\n",
            " 'seven of spades' 'six of clubs' 'six of diamonds' 'six of hearts'\n",
            " 'six of spades' 'ten of clubs' 'ten of diamonds' 'ten of hearts'\n",
            " 'ten of spades' 'three of clubs' 'three of diamonds' 'three of hearts'\n",
            " 'three of spades' 'two of clubs' 'two of diamonds' 'two of hearts'\n",
            " 'two of spades']\n",
            "Shape of one-hot encoded labels: (7624, 53)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0.]\n",
            "-----PROCESSING VALIDATION DATA-----\n",
            "Number of unique labels: 53\n",
            "Unique labels: ['ace of clubs' 'ace of diamonds' 'ace of hearts' 'ace of spades'\n",
            " 'eight of clubs' 'eight of diamonds' 'eight of hearts' 'eight of spades'\n",
            " 'five of clubs' 'five of diamonds' 'five of hearts' 'five of spades'\n",
            " 'four of clubs' 'four of diamonds' 'four of hearts' 'four of spades'\n",
            " 'jack of clubs' 'jack of diamonds' 'jack of hearts' 'jack of spades'\n",
            " 'joker' 'king of clubs' 'king of diamonds' 'king of hearts'\n",
            " 'king of spades' 'nine of clubs' 'nine of diamonds' 'nine of hearts'\n",
            " 'nine of spades' 'queen of clubs' 'queen of diamonds' 'queen of hearts'\n",
            " 'queen of spades' 'seven of clubs' 'seven of diamonds' 'seven of hearts'\n",
            " 'seven of spades' 'six of clubs' 'six of diamonds' 'six of hearts'\n",
            " 'six of spades' 'ten of clubs' 'ten of diamonds' 'ten of hearts'\n",
            " 'ten of spades' 'three of clubs' 'three of diamonds' 'three of hearts'\n",
            " 'three of spades' 'two of clubs' 'two of diamonds' 'two of hearts'\n",
            " 'two of spades']\n",
            "Shape of one-hot encoded labels: (265, 53)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0.]\n",
            "-----PROCESSING TEST DATA-----\n",
            "Number of unique labels: 53\n",
            "Unique labels: ['ace of clubs' 'ace of diamonds' 'ace of hearts' 'ace of spades'\n",
            " 'eight of clubs' 'eight of diamonds' 'eight of hearts' 'eight of spades'\n",
            " 'five of clubs' 'five of diamonds' 'five of hearts' 'five of spades'\n",
            " 'four of clubs' 'four of diamonds' 'four of hearts' 'four of spades'\n",
            " 'jack of clubs' 'jack of diamonds' 'jack of hearts' 'jack of spades'\n",
            " 'joker' 'king of clubs' 'king of diamonds' 'king of hearts'\n",
            " 'king of spades' 'nine of clubs' 'nine of diamonds' 'nine of hearts'\n",
            " 'nine of spades' 'queen of clubs' 'queen of diamonds' 'queen of hearts'\n",
            " 'queen of spades' 'seven of clubs' 'seven of diamonds' 'seven of hearts'\n",
            " 'seven of spades' 'six of clubs' 'six of diamonds' 'six of hearts'\n",
            " 'six of spades' 'ten of clubs' 'ten of diamonds' 'ten of hearts'\n",
            " 'ten of spades' 'three of clubs' 'three of diamonds' 'three of hearts'\n",
            " 'three of spades' 'two of clubs' 'two of diamonds' 'two of hearts'\n",
            " 'two of spades']\n",
            "Shape of one-hot encoded labels: (265, 53)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "train_folder_path = 'cards-set/train/'\n",
        "valid_folder_path = 'cards-set/valid/'\n",
        "test_folder_path = 'cards-set/test/'\n",
        "# number of images to display for each class\n",
        "preview_num = 5\n",
        "\n",
        "with ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "  # process training data\n",
        "  print(\"-----PROCESSING TRAINING DATA-----\")\n",
        "  preprocessed_train_imgs, train_img_labels, train_files = extract_and_preprocess_images(zip_ref, train_folder_path)\n",
        "  one_hot_encoded_labels_train = one_hot_encode_labels(train_img_labels)\n",
        "  # display_imgs(zip_ref, train_files, \"Training Set\", preview_num)\n",
        "\n",
        "  # process valid data\n",
        "  print(\"-----PROCESSING VALIDATION DATA-----\")\n",
        "  preprocessed_valid_imgs, valid_img_labels, valid_files = extract_and_preprocess_images(zip_ref, valid_folder_path)\n",
        "  one_hot_encoded_labels_valid = one_hot_encode_labels(valid_img_labels)\n",
        "  # display_imgs(zip_ref, valid_files, \"Validation Set\", preview_num)\n",
        "\n",
        "  # process test data\n",
        "  print(\"-----PROCESSING TEST DATA-----\")\n",
        "  preprocessed_test_imgs, test_img_labels, test_files = extract_and_preprocess_images(zip_ref, test_folder_path)\n",
        "  one_hot_encoded_labels_test = one_hot_encode_labels(test_img_labels)\n",
        "  # display_imgs(zip_ref, test_files, \"Test Set\", preview_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4cxVZn_zjem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c876189b-5b31-4180-b84d-a1adb78136c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmentation complete. New training set size: (45744, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create an ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,      # randomly rotate images by up to 20 degrees\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally by up to 20% of the width\n",
        "    height_shift_range=0.2, # randomly shift images vertically by up to 20% of the height\n",
        "    shear_range=0.2,        # apply random shearing transformations\n",
        "    zoom_range=0.2,         # randomly zoom in on images by up to 20%\n",
        "    horizontal_flip=True,   # randomly flip images horizontally\n",
        "    fill_mode='nearest'     # fill in missing pixels with the nearest value\n",
        ")\n",
        "\n",
        "# reshape it to fit the ImageDataGenerator's expected input\n",
        "preprocessed_train_imgs = np.array(preprocessed_train_imgs)\n",
        "\n",
        "# generate augmented images\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "\n",
        "for i in range(len(preprocessed_train_imgs)):\n",
        "    img = preprocessed_train_imgs[i]\n",
        "    label = one_hot_encoded_labels_train[i]  # Assuming you have one-hot encoded labels\n",
        "\n",
        "    # expand dimensions to make it compatible with ImageDataGenerator\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # generate augmented images (adjust the number of augmentations as needed)\n",
        "    for j in range(5):\n",
        "        augmented_img = next(datagen.flow(img, batch_size=1))[0]\n",
        "        augmented_images.append(augmented_img)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "# convert the augmented data to NumPy arrays\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "# concatenate augmented data with original training data\n",
        "all_train_images = np.concatenate((preprocessed_train_imgs, augmented_images), axis=0)\n",
        "all_train_labels = np.concatenate((one_hot_encoded_labels_train, augmented_labels), axis=0)\n",
        "\n",
        "print(\"Augmentation complete. New training set size:\", all_train_images.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FsgzpM3fShd"
      },
      "source": [
        "#**Create Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb90WSn8bQmW",
        "outputId": "47610728-59d3-481b-9888-9b6a62161019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvH1s3ybiix7",
        "outputId": "2d5ed790-65d4-4b9a-d225-ed2be65538e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (45744, 128, 128, 3), (45744, 53)\n",
            "Validation data shape: (265, 128, 128, 3), (265, 53)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_128_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n",
            "Epoch 1/8\n",
            "715/715 [==============================] - 307s 421ms/step - loss: 5.1015 - accuracy: 0.5575 - val_loss: 1.9239 - val_accuracy: 0.8340 - lr: 0.0010\n",
            "Epoch 2/8\n",
            "715/715 [==============================] - 298s 417ms/step - loss: 1.6238 - accuracy: 0.8158 - val_loss: 0.9792 - val_accuracy: 0.9094 - lr: 0.0010\n",
            "Epoch 3/8\n",
            "715/715 [==============================] - 297s 415ms/step - loss: 1.0068 - accuracy: 0.9061 - val_loss: 0.7575 - val_accuracy: 0.9547 - lr: 0.0010\n",
            "Epoch 4/8\n",
            "715/715 [==============================] - 300s 420ms/step - loss: 0.7204 - accuracy: 0.9575 - val_loss: 0.6992 - val_accuracy: 0.9208 - lr: 0.0010\n",
            "Epoch 5/8\n",
            "715/715 [==============================] - 300s 419ms/step - loss: 0.5553 - accuracy: 0.9793 - val_loss: 0.6255 - val_accuracy: 0.9321 - lr: 0.0010\n",
            "Epoch 6/8\n",
            "715/715 [==============================] - 301s 420ms/step - loss: 0.4547 - accuracy: 0.9887 - val_loss: 0.5615 - val_accuracy: 0.9434 - lr: 0.0010\n",
            "Epoch 7/8\n",
            "715/715 [==============================] - 297s 415ms/step - loss: 0.3872 - accuracy: 0.9925 - val_loss: 0.4825 - val_accuracy: 0.9509 - lr: 0.0010\n",
            "Epoch 8/8\n",
            "715/715 [==============================] - 302s 423ms/step - loss: 0.3362 - accuracy: 0.9956 - val_loss: 0.4407 - val_accuracy: 0.9509 - lr: 0.0010\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 0.4407 - accuracy: 0.9509\n",
            "Validation accuracy: 0.9509434103965759\n"
          ]
        }
      ],
      "source": [
        "# convert lists to numpy arrays if they aren't already\n",
        "X_train = np.array(all_train_images)\n",
        "y_train = np.array(all_train_labels)\n",
        "X_val = np.array(preprocessed_valid_imgs)\n",
        "y_val = np.array(one_hot_encoded_labels_valid)\n",
        "\n",
        "# ensure the shapes are correct\n",
        "print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}, {y_val.shape}\")\n",
        "\n",
        "# create pre-trained model\n",
        "base_model = tf.keras.applications.MobileNet(\n",
        "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=\"max\",\n",
        ")\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
        "    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n",
        "                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n",
        "    Dropout(rate= 0.5),\n",
        "    Dense(53, activation= 'softmax') # assuming 53 unique classes for each card\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# define learning rate reduction and early stopping\n",
        "lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=0.00001)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# train the model with callbacks\n",
        "history = model.fit(X_train, y_train, epochs=8, validation_data=(X_val, y_val),\n",
        "                    batch_size=64, callbacks=[lr_reduction, early_stopping])\n",
        "\n",
        "# evaluate the model\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation accuracy: {val_accuracy}')\n",
        "\n",
        "# save model architecture to JSON\n",
        "model_json = model.to_json()\n",
        "\n",
        "# save the JSON model to drive\n",
        "with open(\"/content/drive/MyDrive/ml-project/playing-cards-model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# save weights to the same directory\n",
        "model.save_weights(\"/content/drive/MyDrive/ml-project/playing-cards-model_weights.h5\")\n",
        "\n",
        "# model.save('/content/drive/MyDrive/ml-project/playing-cards-classification-model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OKT9faz9OkH"
      },
      "source": [
        "# Testing Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNjtG5r0_cFa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSjwaLau9ZVF",
        "outputId": "72afe64a-3f28-48b5-f5be-7be9f701aae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data shape: (265, 128, 128, 3), (265, 53)\n",
            "9/9 [==============================] - 1s 52ms/step - loss: 0.4745 - accuracy: 0.9434\n",
            "Test accuracy: 0.9433962106704712\n"
          ]
        }
      ],
      "source": [
        "# convert lists to numpy arrays\n",
        "X_test = np.array(preprocessed_test_imgs)\n",
        "y_test = np.array(one_hot_encoded_labels_test)\n",
        "\n",
        "# ensure the shapes are correct\n",
        "print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# load the model\n",
        "model = load_model('/content/drive/MyDrive/ml-project/classification-test-model.h5')\n",
        "\n",
        "# evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}